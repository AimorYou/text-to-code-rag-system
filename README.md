# Система поиска релевантного кода на Python

Система семантического поиска фрагментов кода Python с использованием би-энкодерной нейросетевой архитектуры.

## Описание

Этот проект реализует прототип системы семантического поиска релевантных фрагментов кода Python на основе запросов на естественном языке. Система использует би-энкодерную архитектуру с отдельными энкодерами для текста и кода, обученными с помощью контрастного обучения.

## Архитектура

### Модель

**Би-энкодерная модель** с двумя независимыми энкодерами:

- **Текстовый энкодер**: DistilBERT для кодирования описаний на естественном языке
- **Кодовый энкодер**: CodeBERT для кодирования фрагментов кода Python

Оба энкодера создают 768-мерные эмбеддинги, которые обучаются с использованием контрастной функции потерь (InfoNCE) для минимизации расстояния между соответствующими парами текст-код.

### Формат входных и выходных данных

**Вход модели:**

- Текстовое описание: Строка произвольной длины
- Фрагмент кода: Строка произвольной длины (код на Python)

**Выход модели:**

- Текстовое векторное представление: Вектор из 768 чисел (float32)
- Кодовое векторное представление: Вектор из 768 чисел (float32)

**Вход системы:**

- Пользовательский текстовый запрос
- Коллекция предварительно вычисленных эмбеддингов кода

**Выход системы:**

- Список из k наиболее релевантных фрагментов кода:

```json
[
  { "code": "...", "similarity": 0.87 },
  { "code": "...", "similarity": 0.85 }
]
```

## Метрики

Система оценивается с использованием:

- **Recall@K**: Доля запросов, где корректный фрагмент кода попадает в топ-K результатов
- **MRR (Mean Reciprocal Rank)**: Среднее положение правильного ответа в списке результатов

## Датасет

**CodeSearchNet**: Крупномасштабный датасет для поиска кода

- ~2 млн пар текст-код
- 6 языков программирования (используется подмножество Python: 10k примеров)
- Размер: ~20 ГБ в необработанном виде
- [GitHub репозиторий](https://github.com/github/CodeSearchNet)
- [HuggingFace датасет](https://huggingface.co/datasets/espejelomar/code_search_net_python_10000_examples)

### Разбиение данных

- Train / Validation / Test = 80% / 10% / 10%
- Случайное разбиение с фиксированным seed для воспроизводимости
- Разбиение по функциям (а не по строкам) для предотвращения утечки

## Установка

### Требования

- Python 3.12+
- Git
- uv (для управления зависимостями)

### Инструкция по установке

1. **Клонируйте репозиторий**

```bash
git clone https://github.com/AimorYou/text-to-code-rag-system.git
cd text-to-code-rag-system
```

2. **Установите uv** (если еще не установлен)

```bash
pip install uv
```

3. **Установите зависимости**

```bash
# Основные зависимости
uv sync

# С dev зависимостями (pre-commit, ruff, pytest)
uv sync --all-extras
```

4. **Установите pre-commit хуки**

```bash
uv run pre-commit install
```

5. **Проверьте установку**

```bash
uv run pre-commit run -a
```

### Настройка MLflow

Запустите MLflow tracking сервер (в отдельном терминале):

```bash
uv run mlflow server --host 127.0.0.1 --port 8080
```

## Управление данными с DVC

Проект использует DVC (Data Version Control) для управления датасетом.

### Автоматический режим

Данные автоматически загружаются при запуске `train` или `infer`:

1. Проверяется наличие данных в DVC remote
2. Если данные есть - они скачиваются через `dvc pull`
3. Если нет - загружаются из HuggingFace и добавляются в DVC
4. Автоматически делается `dvc push` в настроенный remote

## Запуск проекта

### Обучение

Обучите модель с конфигурацией по умолчанию (Обучаются только адаптеры):

```bash
uv run text-to-code-rag train
```

Для более качественного обучения можно дообучать все параметры:

```bash
uv run text-to-code-rag train --config_name=train model=base_model
```

### Инференс

Примените модель с конфигурацией по умолчанию:

```bash
uv run text-to-code-rag infer
```

### Тестирование

Запуск тестов:

```bash
uv run pytest
```

С покрытием:

```bash
uv run pytest --cov=text_to_code_rag --cov-report=html
```

## Лицензия

MIT License - см. файл LICENSE для деталей.
